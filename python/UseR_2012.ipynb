{
 "metadata": {
  "name": "UseR_2012"
 },
 "nbformat": 3,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "source": [
      "# Python for R Programmers\n",
      "\n",
      "### Christopher Fonnesbeck\n",
      "### Vanderbilt University\n",
      "#### 14 June, 2012"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "source": [
      "What is Python?"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "## Numpy and Scipy"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "## Matplotlib"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "## IPython"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "## Pandas"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "## Cython and f2py"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "\t      SUBROUTINE bernoulli(x,p,nx,np,like)\n",
      "\n",
      "\tcf2py logical dimension(nx),intent(in) :: x\n",
      "\tcf2py double precision dimension(np),intent(in) :: p\n",
      "\tcf2py integer intent(hide),depend(x) :: nx=len(x)\n",
      "\tcf2py integer intent(hide),depend(p),check(len(p)==1 || len(p)==len(x)):: np=len(p)\n",
      "\tcf2py double precision intent(out) :: like\n",
      "\tcf2py threadsafe\n",
      "\n",
      "\t      IMPLICIT NONE\n",
      "\n",
      "\t      INTEGER np,nx,i\n",
      "\t      DOUBLE PRECISION p(np), ptmp, like\n",
      "\t      LOGICAL x(nx)\n",
      "\t      LOGICAL not_scalar_p\n",
      "\t      DOUBLE PRECISION infinity\n",
      "\t      PARAMETER (infinity = 1.7976931348623157d308)\n",
      "\n",
      "\tC     Check parameter size\n",
      "\t      not_scalar_p = (np .NE. 1)\n",
      "\n",
      "\t      like = 0.0\n",
      "\t      ptmp = p(1)\n",
      "\t      do i=1,nx\n",
      "\t        if (not_scalar_p) ptmp = p(i)\n",
      "\t        if (ptmp .LT. 0.0) then\n",
      "\t          like = -infinity\n",
      "\t          RETURN\n",
      "\t        endif\n",
      "\n",
      "\t        if (x(i)) then\n",
      "\t          like = like + dlog(ptmp)\n",
      "\t        else\n",
      "\t          like = like + dlog(1.0D0 - ptmp)\n",
      "\t        endif\n",
      "\n",
      "\t      enddo\n",
      "\t      return\n",
      "\t      END\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "source": [
      "Benchmark example: Gibbs sampling"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "Gibbs sampler for function:\n",
      "\n",
      "$$f(x,y) = x x^2 \\exp(-xy^2 - y^2 + 2y - 4x)$$\n",
      "\n",
      "using conditional distributions:\n",
      "    \n",
      "$$x|y \\sim Gamma(3, y^2 +4)$$\n",
      "$$y|x \\sim Normal(\\frac{1}{1+x}, \\frac{1}{2(1+x)})$$"
     ]
    },
    {
     "cell_type": "code",
     "input": [
      "from numpy import zeros, random, sqrt\n",
      "gamma = random.gamma\n",
      "normal = random.normal\n",
      "\n",
      "def pygibbs(N=20000, thin=200):\n",
      "    mat = zeros((N,2))\n",
      "    x,y = mat[0]\n",
      "    for i in range(N):\n",
      "        for j in range(thin):\n",
      "            x = gamma(3, y**2 + 4)\n",
      "            y = normal(1./(x+1), 1./sqrt(2*(x+1)))\n",
      "        mat[i] = x,y\n",
      "\n",
      "    return mat"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "input": [
      "timeit pygibbs(20000, 200)"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 22.6 s per loop\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "input": [
      "%load_ext cythonmagic"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "input": [
      "%%cython -lm -lgsl -lgslcblas\n",
      "\n",
      "cimport cython\n",
      "import numpy as np\n",
      "from numpy cimport *\n",
      "\n",
      "cdef extern from \"math.h\":\n",
      "    double sqrt(double) \n",
      "  \n",
      "cdef extern from \"gsl/gsl_rng.h\":\n",
      "    ctypedef struct gsl_rng_type\n",
      "    ctypedef struct gsl_rng\n",
      "\n",
      "    gsl_rng_type *gsl_rng_mt19937\n",
      "    gsl_rng *gsl_rng_alloc(gsl_rng_type * T) nogil\n",
      "  \n",
      "cdef extern from \"gsl/gsl_randist.h\":\n",
      "    double gamma \"gsl_ran_gamma\"(gsl_rng * r,double,double)\n",
      "    double gaussian \"gsl_ran_gaussian\"(gsl_rng * r,double)\n",
      "  \n",
      "cdef gsl_rng *r = gsl_rng_alloc(gsl_rng_mt19937)\n",
      "\n",
      "@cython.wraparound(False)\n",
      "@cython.boundscheck(False)\n",
      "def gibbs(int N=20000,int thin=500):\n",
      "    cdef: \n",
      "        double x=0\n",
      "        double y=0\n",
      "        int i, j\n",
      "        ndarray[float64_t, ndim=2] samples\n",
      "\n",
      "    samples = np.empty((N,thin))\n",
      "    for i from 0 <= i < N:\n",
      "        for j from 0 <= j < thin:\n",
      "            x = gamma(r,3,1.0/(y*y+4))\n",
      "            y = gaussian(r,1.0/sqrt(x+1))\n",
      "        samples[i,0] = x\n",
      "        samples[i,1] = y\n",
      "    return samples"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "input": [
      "timeit gibbs(20000, 200)"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 1.05 s per loop\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "input": [
      "a = gibbs(2000, 20)\n",
      "a.shape"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "(2000, 20)"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 2,
     "source": [
      "Cython parallel"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "Before running the next cell, make sure you have first started your cluster, you can use the [clusters tab in the dashboard](/#tab2) to do so.  Because this example transfers lots of large arrays, we recommend that you first configure your cluster to use the 'NoDB' hub messaging support, which removes a few features but has the lowest memory footprint.  You can do so by putting in your IPython profile directory a file called `ipcontroller_config.py` that contains simply:\n",
      "\n",
      "    # Configuration file for ipcontroller.\n",
      "    c = get_config()\n",
      "    # The class to use for the DB backend\n",
      "    c.HubFactory.db_class = 'IPython.parallel.controller.dictdb.NoDB'\n",
      "\n",
      "See [the IPython docs](http://ipython.org/ipython-doc/dev/parallel/parallel_db.html?#cost) for further details."
     ]
    },
    {
     "cell_type": "code",
     "input": [
      "from IPython.parallel import Client\n",
      "rc = Client()\n",
      "dv = rc[:]\n",
      "dv.block = True\n",
      "dv.activate()"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "source": [
      "Now, we load the cython magic on all engines and execute the cython magic as well on all engines:"
     ]
    },
    {
     "cell_type": "code",
     "input": [
      "%px %load_ext cythonmagic"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Parallel execution on engine(s): [0, 1, 2, 3]\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "input": [
      "%%px\n",
      "%%cython -lm -lgsl -lgslcblas\n",
      "\n",
      "cimport cython\n",
      "import numpy as np\n",
      "from numpy cimport *\n",
      "\n",
      "cdef extern from \"math.h\":\n",
      "    double sqrt(double) \n",
      "  \n",
      "cdef extern from \"gsl/gsl_rng.h\":\n",
      "    ctypedef struct gsl_rng_type\n",
      "    ctypedef struct gsl_rng\n",
      "\n",
      "    gsl_rng_type *gsl_rng_mt19937\n",
      "    gsl_rng *gsl_rng_alloc(gsl_rng_type * T) nogil\n",
      "  \n",
      "cdef extern from \"gsl/gsl_randist.h\":\n",
      "    double gamma \"gsl_ran_gamma\"(gsl_rng * r,double,double)\n",
      "    double gaussian \"gsl_ran_gaussian\"(gsl_rng * r,double)\n",
      "  \n",
      "cdef gsl_rng *r = gsl_rng_alloc(gsl_rng_mt19937)\n",
      "\n",
      "@cython.wraparound(False)\n",
      "@cython.boundscheck(False)\n",
      "def gibbs(int N=20000,int thin=500):\n",
      "    cdef: \n",
      "        double x=0\n",
      "        double y=0\n",
      "        int i, j\n",
      "        ndarray[float64_t, ndim=2] samples\n",
      "\n",
      "    samples = np.empty((N,thin))\n",
      "    for i from 0 <= i < N:\n",
      "        for j from 0 <= j < thin:\n",
      "            x = gamma(r,3,1.0/(y*y+4))\n",
      "            y = gaussian(r,1.0/sqrt(x+1))\n",
      "        samples[i,0] = x\n",
      "        samples[i,1] = y\n",
      "    return samples"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Parallel execution on engine(s): [0, 1, 2, 3]\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "source": [
      "Divide the array by the number of nodes.  In this case they divide evenly, a more general partitioning of sizes is easy to do as well."
     ]
    },
    {
     "cell_type": "code",
     "input": [
      "N = 20000\n",
      "thin = 200\n",
      "n = N/len(rc.ids)\n",
      "dv.push(dict(n=n, thin=thin))\n",
      "# Let's just confirm visually we got what we expect\n",
      "dv['n']"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "[5000, 5000, 5000, 5000]"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "source": [
      "We can time purely the execution of the gibbs sampler on the remote nodes"
     ]
    },
    {
     "cell_type": "code",
     "input": [
      "%%timeit\n",
      "dv.execute('gibbs(n, thin)')"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 320 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "source": [
      "But a more realistic (and costly) benchmark must also include the cost of bringing the results back from the cluster engines to our local namespace.  For that, we assign the call to the variable `a` on each node and then use the view's `gather` method to pull them back in:"
     ]
    },
    {
     "cell_type": "code",
     "input": [
      "%%timeit\n",
      "dv.execute('a = gibbs(n, thin)')\n",
      "a = dv.gather('a')"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 607 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "source": [
      "First, let's confirm the returned `a` has the shape we expect:"
     ]
    },
    {
     "cell_type": "code",
     "input": [
      "a.shape"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "(2000, 20)"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "source": [
      "Here we see how on a 4-core machine we get close to a 4-fold speedup on pure execution, but once we have to pay the price of communicating the results back to the local engine, the benefit is less.  In a real parallel application, much of the art of optimization comes in trying to keep the movement of large amounts of data to a minimum, as communication is always *much* more expensive than computation in today's architectures."
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "## Gibbs Sampler Shootout\n",
      "\n",
      "Timed on a 11\" MacBook Air (1.8 GHz Intel Core i7)\n",
      "\n",
      "* Python 2.7.1, Cython 0.16\n",
      "* Julia 0.0.0 (!!)\n",
      "* R 2.14.1, Rcpp 0.9.10\n",
      "\n",
      "Elapsed time for 10 replications of the Gibbs sampler code run for 2 million iterations."
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "<TABLE cellpadding=\"4\" style=\"border: 1px solid #000000; border-collapse: collapse;\" border=\"1\"> <TR>  <TH>model</TH>  <TH>elapsed</TH>  <TH>relative</TH> </TR> <TR bgcolor=\"#FFFF00\">  <TD>Julia distributed</TD>  <TD>3.38</TD>  <TD>1.0</TD> </TR> <TR>  <TD>GSLGibbs</TD>  <TD>5.46</TD>  <TD>1.6</TD> </TR> <TR bgcolor=\"#00FFFF\">  <TD>Cython</TD>  <TD>5.58</TD>  <TD>1.7</TD> </TR> <TR bgcolor=\"#FFFF00\">  <TD>Julia native RNG</TD>  <TD>7.03</TD>  <TD>2.1</TD> </TR> <TR>  <TD>RcppGibbs</TD>  <TD>9.95</TD>  <TD>2.9</TD> </TR> <TR>  <TD>BoostGibbs</TD>  <TD>10.65</TD>  <TD>3.2</TD> </TR> <TR bgcolor=\"#FFFF00\">  <TD>Julia libRMath</TD>  <TD>17.27</TD>  <TD>5.1</TD> </TR> <TR bgcolor=\"#00FFFF\">  <TD>Pure Python</TD>  <TD>278.51</TD>  <TD>82.4</TD> </TR> <TR>  <TD>RCgibbs</TD>  <TD>328.56</TD>  <TD>97.2</TD> </TR> <TR>  <TD>Rgibbs</TD>  <TD>419.87</TD>  <TD>124.2</TD> </TR></TABLE>"
     ]
    },
    {
     "cell_type": "code",
     "input": [],
     "language": "python",
     "outputs": []
    }
   ]
  }
 ]
}